{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks and Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Kiprono\n",
    "Lewis William"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# select categories and load the training and test data\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med', 'sci.space',\n",
    "              'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "# load training and test data\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and download NLTK (natural language toolkit for more expanded libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to vectors of word counts\n",
    "\n",
    "# import and use CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#count_vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate label vectors for training and multiclass ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(twenty_train.target)\n",
    "train_vTarget=lb.transform(twenty_train.target)\n",
    "test_vTarget=lb.transform(twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 2, ..., 1, 7, 6], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ANN (discuss parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "10\n",
      "[0 0 0 0 1 0 0 0 0 0]\n",
      "-----------\n",
      "[0 0 0 0 1 0 0 0 0 0]\n",
      "0.8526831785345718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf = MLPClassifier(activation='logistic', solver='adam', max_iter=50, alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "clf.fit(X_train_counts, train_vTarget)\n",
    "print(clf.classes_)\n",
    "print(clf.n_outputs_)\n",
    "\n",
    "# make predictions on test data\n",
    "clf.out_activation_ = 'softmax'\n",
    "predicted = clf.predict(X_test_counts)\n",
    "\n",
    "print(predicted[1])\n",
    "print('-----------')\n",
    "print(test_vTarget[1])\n",
    "predicted = lb.inverse_transform(predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526831785345718\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.38      0.92      0.54       319\n",
      "         comp.graphics       0.94      0.84      0.89       389\n",
      "          misc.forsale       0.94      0.88      0.91       390\n",
      "             rec.autos       0.97      0.82      0.89       396\n",
      "       rec.motorcycles       1.00      0.89      0.94       398\n",
      "    rec.sport.baseball       0.98      0.86      0.92       397\n",
      "      rec.sport.hockey       0.99      0.95      0.97       399\n",
      "               sci.med       0.97      0.67      0.79       396\n",
      "             sci.space       1.00      0.80      0.89       394\n",
      "soc.religion.christian       0.95      0.91      0.93       398\n",
      "\n",
      "              accuracy                           0.85      3876\n",
      "             macro avg       0.91      0.85      0.87      3876\n",
      "          weighted avg       0.92      0.85      0.87      3876\n",
      "\n",
      "[[293   1   0   0   0   1   0   5   0  19]\n",
      " [ 59 325   3   0   0   1   0   0   1   0]\n",
      " [ 40   3 343   4   0   0   0   0   0   0]\n",
      " [ 62   2   5 326   0   0   0   1   0   0]\n",
      " [ 35   0   4   4 355   0   0   0   0   0]\n",
      " [ 49   0   3   0   0 342   3   0   0   0]\n",
      " [ 19   0   0   0   0   2 378   0   0   0]\n",
      " [120   3   3   2   0   1   0 267   0   0]\n",
      " [ 66   9   1   1   0   0   0   3 314   0]\n",
      " [ 32   2   1   0   0   1   0   0   0 362]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9045407636738906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='logistic', solver='adam', max_iter=50, alpha=1e-5, hidden_layer_sizes=(25,), random_state=1)\n",
    "clf.fit(X_train_counts, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "clf.out_activation_ = 'softmax'\n",
    "predicted = clf.predict(X_test_counts)\n",
    "\n",
    "predicted = lb.inverse_transform(predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9045407636738906\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.56      0.88      0.69       319\n",
      "         comp.graphics       0.93      0.88      0.90       389\n",
      "          misc.forsale       0.92      0.93      0.93       390\n",
      "             rec.autos       0.96      0.89      0.92       396\n",
      "       rec.motorcycles       1.00      0.93      0.96       398\n",
      "    rec.sport.baseball       0.97      0.93      0.95       397\n",
      "      rec.sport.hockey       0.97      0.97      0.97       399\n",
      "               sci.med       0.96      0.81      0.88       396\n",
      "             sci.space       0.97      0.89      0.93       394\n",
      "soc.religion.christian       0.92      0.94      0.93       398\n",
      "\n",
      "              accuracy                           0.90      3876\n",
      "             macro avg       0.92      0.90      0.91      3876\n",
      "          weighted avg       0.92      0.90      0.91      3876\n",
      "\n",
      "[[280   1   0   0   0   1   0   7   3  27]\n",
      " [ 27 341   8   3   0   4   2   0   4   0]\n",
      " [ 19   3 362   5   0   0   1   0   0   0]\n",
      " [ 31   2   8 352   1   0   0   1   1   0]\n",
      " [ 16   0   4   7 371   0   0   0   0   0]\n",
      " [ 17   0   3   0   0 368   8   0   1   0]\n",
      " [  5   0   0   0   0   6 387   0   0   1]\n",
      " [ 64   6   3   0   0   1   1 319   0   2]\n",
      " [ 24  12   3   0   0   0   0   4 350   1]\n",
      " [ 15   2   1   0   0   1   0   1   2 376]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_sw = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_sw_counts = count_vect_sw.fit_transform(twenty_train.data)\n",
    "X_test_sw_counts = count_vect_sw.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847265221878225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='logistic', solver='adam', max_iter=50, alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "clf.fit(X_train_sw_counts, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "clf.out_activation_ = 'softmax'\n",
    "predicted = clf.predict(X_test_sw_counts)\n",
    "\n",
    "predicted = lb.inverse_transform(predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847265221878225\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.36      0.91      0.52       319\n",
      "         comp.graphics       0.96      0.79      0.87       389\n",
      "          misc.forsale       0.97      0.83      0.89       390\n",
      "             rec.autos       0.98      0.82      0.89       396\n",
      "       rec.motorcycles       0.99      0.92      0.95       398\n",
      "    rec.sport.baseball       0.98      0.86      0.92       397\n",
      "      rec.sport.hockey       0.99      0.91      0.95       399\n",
      "               sci.med       0.98      0.70      0.82       396\n",
      "             sci.space       0.98      0.81      0.89       394\n",
      "soc.religion.christian       0.94      0.93      0.93       398\n",
      "\n",
      "              accuracy                           0.85      3876\n",
      "             macro avg       0.91      0.85      0.86      3876\n",
      "          weighted avg       0.92      0.85      0.87      3876\n",
      "\n",
      "[[290   1   0   0   0   1   0   4   1  22]\n",
      " [ 75 309   1   0   0   1   0   0   2   1]\n",
      " [ 59   1 324   5   0   1   0   0   0   0]\n",
      " [ 63   1   5 323   2   0   0   1   1   0]\n",
      " [ 28   0   2   3 365   0   0   0   0   0]\n",
      " [ 52   0   1   0   0 341   2   0   1   0]\n",
      " [ 31   0   0   0   0   2 365   0   1   0]\n",
      " [113   1   1   0   0   1   1 279   0   0]\n",
      " [ 66   7   1   0   0   0   0   1 319   0]\n",
      " [ 27   1   0   0   0   1   0   0   0 369]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "#stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "stemmed_count_vect = StemmedCountVectorizer()\n",
    "X_train_stem_counts = stemmed_count_vect.fit_transform(twenty_train.data)\n",
    "X_test_stem_counts = stemmed_count_vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606811145510835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='logistic', solver='adam', max_iter=50, alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "clf.fit(X_train_stem_counts, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "clf.out_activation_ = 'softmax'\n",
    "predicted = clf.predict(X_test_stem_counts)\n",
    "\n",
    "predicted = lb.inverse_transform(predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606811145510835\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.40      0.91      0.55       319\n",
      "         comp.graphics       0.94      0.84      0.89       389\n",
      "          misc.forsale       0.94      0.86      0.90       390\n",
      "             rec.autos       0.97      0.86      0.91       396\n",
      "       rec.motorcycles       1.00      0.89      0.94       398\n",
      "    rec.sport.baseball       0.99      0.87      0.93       397\n",
      "      rec.sport.hockey       0.99      0.92      0.95       399\n",
      "               sci.med       0.97      0.73      0.83       396\n",
      "             sci.space       0.98      0.83      0.90       394\n",
      "soc.religion.christian       0.95      0.90      0.92       398\n",
      "\n",
      "              accuracy                           0.86      3876\n",
      "             macro avg       0.91      0.86      0.87      3876\n",
      "          weighted avg       0.92      0.86      0.88      3876\n",
      "\n",
      "[[291   0   0   0   0   1   0   5   3  19]\n",
      " [ 50 328   6   0   0   0   1   0   3   1]\n",
      " [ 48   3 335   4   0   0   0   0   0   0]\n",
      " [ 47   1   6 340   0   0   0   1   1   0]\n",
      " [ 36   0   3   5 354   0   0   0   0   0]\n",
      " [ 47   0   0   0   0 347   3   0   0   0]\n",
      " [ 28   0   0   0   0   3 368   0   0   0]\n",
      " [100   4   4   0   0   0   0 288   0   0]\n",
      " [ 54  11   1   0   0   0   0   2 326   0]\n",
      " [ 34   1   1   0   0   1   0   1   1 359]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to a TF-IDF representation (Note change to max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# clf_2 = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771929824561403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='logistic', solver='adam', max_iter=100, alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "clf.fit(X_train_tfidf, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "clf.out_activation_ = 'softmax'\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "predicted = lb.inverse_transform(predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771929824561403\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.43      0.90      0.58       319\n",
      "         comp.graphics       0.95      0.86      0.90       389\n",
      "          misc.forsale       0.96      0.89      0.92       390\n",
      "             rec.autos       0.97      0.86      0.91       396\n",
      "       rec.motorcycles       0.99      0.89      0.94       398\n",
      "    rec.sport.baseball       0.98      0.91      0.94       397\n",
      "      rec.sport.hockey       0.98      0.96      0.97       399\n",
      "               sci.med       0.97      0.73      0.83       396\n",
      "             sci.space       0.99      0.85      0.91       394\n",
      "soc.religion.christian       0.94      0.93      0.94       398\n",
      "\n",
      "              accuracy                           0.88      3876\n",
      "             macro avg       0.92      0.88      0.89      3876\n",
      "          weighted avg       0.93      0.88      0.89      3876\n",
      "\n",
      "[[287   0   0   0   1   1   0   4   2  24]\n",
      " [ 52 334   2   0   0   1   0   0   0   0]\n",
      " [ 33   3 348   4   1   0   1   0   0   0]\n",
      " [ 47   1   6 339   1   0   0   1   1   0]\n",
      " [ 36   0   3   5 354   0   0   0   0   0]\n",
      " [ 31   0   1   0   0 360   5   0   0   0]\n",
      " [  9   0   0   0   0   4 384   0   1   1]\n",
      " [ 97   5   4   0   0   1   0 289   0   0]\n",
      " [ 50   8   0   0   0   0   0   3 333   0]\n",
      " [ 22   2   0   0   0   1   0   0   1 372]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the search for a good ANN model on just the comp.* subset of newsgroups\n",
    "\n",
    "### Make the following choices sequentially (1) hidden layer sizes, (2) include or ignore stopwords, (3) count vectors vs tfidf vectors, and then (4) stemming or not. I suggest using max_iter of at least 100 (default is 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gridsearch for hidden layer sizes\n",
    "  -   save into variable\n",
    "- try with and without stopwords and keep the best performing in a variable\n",
    "- try with count vectors, tfidf and keep the best performing in a variable\n",
    "- try with stemming and without and keep best performing in a variable\n",
    "- max_iter >= 100\n",
    "- don't hard code best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories com.*\n",
    "comp_categories = ['comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x']\n",
    "# load training data\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=comp_categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=comp_categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(twenty_train.target)\n",
    "train_vTarget=lb.transform(twenty_train.target)\n",
    "test_vTarget=lb.transform(twenty_test.target)\n",
    "\n",
    "clfa = MLPClassifier(activation='logistic', solver='adam', max_iter=100, alpha=1e-5, hidden_layer_sizes= (15,), random_state=1)\n",
    "clfb = MLPClassifier(activation='logistic', solver='adam', max_iter=100, alpha=1e-5, hidden_layer_sizes= (30,), random_state=1)\n",
    "clfc = MLPClassifier(activation='logistic', solver='adam', max_iter=100, alpha=1e-5, hidden_layer_sizes= (55,), random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(55,),\n",
      "              max_iter=100, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def bestClf(a,b,c):\n",
    "    a.fit(X_train_counts, train_vTarget)\n",
    "    b.fit(X_train_counts, train_vTarget)\n",
    "    c.fit(X_train_counts, train_vTarget)\n",
    "    \n",
    "    a.out_activation_ = 'softmax'\n",
    "    b.out_activation_ = 'softmax'\n",
    "    c.out_activation_ = 'softmax'\n",
    "    \n",
    "    predicted_a = a.predict(X_test_counts)\n",
    "    predicted_b = b.predict(X_test_counts)\n",
    "    predicted_c = c.predict(X_test_counts)\n",
    "    \n",
    "    predicted_a = lb.inverse_transform(predicted_a)\n",
    "    predicted_b = lb.inverse_transform(predicted_b)\n",
    "    predicted_c= lb.inverse_transform(predicted_c)\n",
    "\n",
    "    \n",
    "    acc_a = np.mean(predicted_a == twenty_test.target)\n",
    "    acc_b = np.mean(predicted_b == twenty_test.target)\n",
    "    acc_c = np.mean(predicted_c == twenty_test.target)\n",
    "    best_acc = max(acc_a, acc_b, acc_c)\n",
    "    best_hls = a\n",
    "#     print(acc_a,acc_b,acc_c)\n",
    "    if (best_acc == acc_b):\n",
    "        best_acc = acc_b\n",
    "        best_hls = b\n",
    "#         print(best_acc,best_hls)\n",
    "    if (best_acc == acc_c):\n",
    "        best_acc = acc_c\n",
    "        best_hls = c\n",
    "#         print(best_acc,best_hls)\n",
    "    else:\n",
    "        best_acc = acc_a\n",
    "        best_hls = a\n",
    "#         print(best_acc,best_hls)\n",
    "    return(best_hls)\n",
    "best_clf = bestClf(clfa,clfb,clfc)\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predict = best_clf.predict(X_test_counts)\n",
    "best_predict = lb.inverse_transform(best_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7979539641943734\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.70      0.84      0.76       389\n",
      " comp.os.ms-windows.misc       0.80      0.73      0.76       394\n",
      "comp.sys.ibm.pc.hardware       0.80      0.79      0.80       392\n",
      "   comp.sys.mac.hardware       0.84      0.86      0.85       385\n",
      "          comp.windows.x       0.89      0.78      0.83       395\n",
      "\n",
      "                accuracy                           0.80      1955\n",
      "               macro avg       0.80      0.80      0.80      1955\n",
      "            weighted avg       0.80      0.80      0.80      1955\n",
      "\n",
      "[[325  17   7  18  22]\n",
      " [ 46 286  37  12  13]\n",
      " [ 19  29 311  29   4]\n",
      " [ 22   7  25 330   1]\n",
      " [ 55  20   7   5 308]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(best_predict == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, best_predict,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, best_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933503836317135\n",
      "0.7933503836317135\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.68      0.84      0.75       389\n",
      " comp.os.ms-windows.misc       0.78      0.72      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.80      0.80      0.80       392\n",
      "   comp.sys.mac.hardware       0.85      0.85      0.85       385\n",
      "          comp.windows.x       0.89      0.76      0.82       395\n",
      "\n",
      "                accuracy                           0.79      1955\n",
      "               macro avg       0.80      0.79      0.79      1955\n",
      "            weighted avg       0.80      0.79      0.79      1955\n",
      "\n",
      "[[327  19   8  16  19]\n",
      " [ 52 285  35  11  11]\n",
      " [ 22  29 313  24   4]\n",
      " [ 24   7  25 327   2]\n",
      " [ 55  25  10   6 299]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "count_vect_sw = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_sw_counts = count_vect_sw.fit_transform(twenty_train.data)\n",
    "X_test_sw_counts = count_vect_sw.transform(twenty_test.data)\n",
    "\n",
    "sw_clf = best_clf\n",
    "sw_clf.fit(X_train_sw_counts, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "sw_clf.out_activation_ = 'softmax'\n",
    "sw_predicted = sw_clf.predict(X_test_sw_counts)\n",
    "\n",
    "sw_predicted = lb.inverse_transform(sw_predicted)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(sw_predicted == twenty_test.target)) \n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(sw_predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, sw_predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, sw_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords or Normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7979539641943734 0.7933503836317135 MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(55,),\n",
      "              max_iter=100, random_state=1) Ignore stopwords for best results\n"
     ]
    }
   ],
   "source": [
    "if (np.mean(best_predict==twenty_test.target)<= np.mean(sw_predicted==twenty_test.target)):\n",
    "    best_clf2 = sw_clf\n",
    "    isSw = \"Stopwords provide the best results\"\n",
    "else:\n",
    "    isSw = \"Ignore stopwords for best results\"\n",
    "    best_clf2 = best_clf\n",
    "print(np.mean(best_predict==twenty_test.target),np.mean(sw_predicted==twenty_test.target), best_clf2, isSw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try TFIDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278772378516624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "tfidf_clf = MLPClassifier(activation='logistic', solver='adam', max_iter=100, alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "tfidf_clf.fit(X_train_tfidf, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "tfidf_clf.out_activation_ = 'softmax'\n",
    "tfidf_pred = tfidf_clf.predict(X_test_tfidf)\n",
    "\n",
    "tfidf_pred = lb.inverse_transform(tfidf_pred)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(tfidf_pred == twenty_test.target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278772378516624\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.45      0.92      0.61       389\n",
      " comp.os.ms-windows.misc       0.89      0.56      0.69       394\n",
      "comp.sys.ibm.pc.hardware       0.90      0.71      0.79       392\n",
      "   comp.sys.mac.hardware       0.95      0.75      0.84       385\n",
      "          comp.windows.x       0.92      0.70      0.80       395\n",
      "\n",
      "                accuracy                           0.73      1955\n",
      "               macro avg       0.82      0.73      0.74      1955\n",
      "            weighted avg       0.82      0.73      0.74      1955\n",
      "\n",
      "[[358   7   5   4  15]\n",
      " [147 222  17   1   7]\n",
      " [ 95  11 277   9   0]\n",
      " [ 85   1   9 289   1]\n",
      " [107   8   1   2 277]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(tfidf_pred == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, tfidf_pred,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, tfidf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is TFIDF better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278772378516624 0.7979539641943734 MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(55,),\n",
      "              max_iter=100, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "best_acc = np.mean(best_predict == twenty_test.target)\n",
    "tfidf_acc = np.mean(tfidf_pred == twenty_test.target)\n",
    "\n",
    "if (best_acc<= tfidf_acc):\n",
    "    best_clf3 = tfidf_clf\n",
    "else:\n",
    "    best_clf3 = best_clf\n",
    "print(tfidf_acc,best_acc,best_clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918158567774936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kipro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_stem_counts = stemmed_count_vect.fit_transform(twenty_train.data)\n",
    "X_test_stem_counts = stemmed_count_vect.transform(twenty_test.data)\n",
    "\n",
    "stem_clf = MLPClassifier(activation='logistic', solver='adam', max_iter=50, alpha=1e-5, hidden_layer_sizes=(55,), random_state=1)\n",
    "stem_clf.fit(X_train_stem_counts, train_vTarget)\n",
    "\n",
    "# make predictions on test data\n",
    "stem_clf.out_activation_ = 'softmax'\n",
    "stem_pred = stem_clf.predict(X_test_stem_counts)\n",
    "\n",
    "stem_pred = lb.inverse_transform(stem_pred)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(stem_pred == twenty_test.target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918158567774936\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.66      0.85      0.75       389\n",
      " comp.os.ms-windows.misc       0.82      0.69      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.80      0.78      0.79       392\n",
      "   comp.sys.mac.hardware       0.85      0.86      0.86       385\n",
      "          comp.windows.x       0.87      0.77      0.82       395\n",
      "\n",
      "                accuracy                           0.79      1955\n",
      "               macro avg       0.80      0.79      0.79      1955\n",
      "            weighted avg       0.80      0.79      0.79      1955\n",
      "\n",
      "[[332  13   8  12  24]\n",
      " [ 54 270  38  14  18]\n",
      " [ 29  26 307  29   1]\n",
      " [ 24   6  21 333   1]\n",
      " [ 61  15   8   5 306]]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print (np.mean(stem_pred == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, stem_pred,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, stem_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Stemming Better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918158567774936 0.7979539641943734 MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(55,),\n",
      "              max_iter=100, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "if (best_acc<= np.mean(stem_pred == twenty_test.target)):\n",
    "    best_clf = stem_clf\n",
    "else:\n",
    "    best_clf\n",
    "print(np.mean(stem_pred == twenty_test.target), best_acc, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming is better technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a29aef9348865955ee6bb3d80a3a53963af477277b943c49e3bad4179e2c33b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
